{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirmed needed dependencies\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Dependencies for geocoordinates generator\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import gmplot\n",
    "\n",
    "# Dependencies for conversion of coordinates to addresses\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "# Dependencies for Zillow data\n",
    "from pyzillow.pyzillow import ZillowWrapper, GetDeepSearchResults\n",
    "\n",
    "# Dependency for Heat Mapper\n",
    "import gmaps\n",
    "\n",
    "\n",
    "# Add config.py file with the following variables and cooresponding Zillow API keys\n",
    "from config import Zapi, Zapi01, Zapi02, Zapi03, Zapi04, Zapi05, Zapi06, Zapi07, Zapi08, Zapi09, Zapi10, Zapi11, Zapi12, Zapi13, Zapi14, Zapi15, Zapi16, Zapi17, Zapi18, Zapi19, Zapi20, Ztroy1, Ztroy2, Ztroy3, Zseth, Zseth2, Zkat, Zval, Zyuta\n",
    "from config import google_API_Key\n",
    "\n",
    "\n",
    "################# ONGOING EDITS TO REQUIREMENTS.MD #################\n",
    "###### IF ANY ERRORS OCCUR RELATING TO MODULES OR CONFIG.PY #######\n",
    "### REFER TO requirements.md TO ENSURE YOU ARE PROPERLY SETUP ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File inputs/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randLatLon_csv = \"./Data/randomLatLon.csv\" \n",
    "addressList_csv = \"./Data/addressList.csv\"\n",
    "masterData_csv = \"./Data/masterData.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geocoordinates of Austin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# this section written by troy bailey.   #\n",
    "# enter uservariables below to determine #\n",
    "# center location, radius of circle, and #\n",
    "# number of geocoordinates to generate.  #\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#### USER VARIABLES ####\n",
    "########################\n",
    "\n",
    "x0 = 30.27444       #### Set center coordiantes in decimal degrees\n",
    "y0 = -97.74028      #### initial coordiantes are location of Texas State Capitol Building\n",
    "\n",
    "radius = 20         #### Set radius in miles\n",
    "\n",
    "points = 40000        #### Set number of lat,lon points to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables and inputs for coordinate calculations\n",
    "lat_lon_list = []\n",
    "radiusInDegrees=radius/69           \n",
    "r = radiusInDegrees\n",
    "points += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate each coordiante point and build a list of lat and lon\n",
    "for i in range(1, points):\n",
    "    u = float(random.uniform(0.0,1.0)) #random number for radius length\n",
    "    v = float(random.uniform(0.0,1.0)) #random number for pi radians\n",
    "    \n",
    "    w = r * math.sqrt(u) #radius length\n",
    "    t = 2 * math.pi * v  #radians\n",
    "    x = w * math.cos(t)  #calculate x coord distance\n",
    "    y = w * math.sin(t)  #calculate y coord distance\n",
    "    \n",
    "    xLat  = x + x0       #offset x by center x\n",
    "    yLon = y + y0        #offset y by center y\n",
    "    \n",
    "    lat_lon_list.append([xLat,yLon])\n",
    "\n",
    "# convert list to dataframe\n",
    "lat_lon_df = pd.DataFrame(lat_lon_list, columns=['lat','lon'])\n",
    "\n",
    "lat_lon_df.head()\n",
    "\n",
    "len(lat_lon_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a CSV file of coordinate points\n",
    "lat_lon_df.to_csv(randLatLon_csv, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot coordinate points on map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section will plot points on a Google map centered at centerPointLat and centerPointLon with a magnification of magFactor\n",
    "# It assumes there is a dataframe with \"lat\" and \"lon\" columns\n",
    "# The resulting map is saved to a file called \n",
    "\n",
    "centerPointLat = 30.27444  #these are the coordinates of the Texas State Capitol building\n",
    "centerPointLon = -97.74028 #these are the coordinates of the Texas State Capitol building\n",
    "magnificationFactor = 10\n",
    "pointColor = \"red\"\n",
    "pointSize = 100\n",
    "mapOutputFile = \"mymap.html\"\n",
    "df = lat_lon_df\n",
    "\n",
    "gmap = gmplot.GoogleMapPlotter(centerPointLat, centerPointLon, magnificationFactor)\n",
    "\n",
    "gmap.scatter(df[\"lat\"], df[\"lon\"], pointColor, size=pointSize, marker=False)\n",
    "\n",
    "gmap.draw(\"./Visuals/\" + mapOutputFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Coordinates to Residential Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "##### Yuta's Blocks #####\n",
    "#########################\n",
    "\n",
    "##### Geopy Nominatim API #####\n",
    "geopy.geocoders.options.default_user_agent = \"ut-group-EPIC\"\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "url = \"https://nominatim.openstreetmap.org/reverse?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test API - Known Residential Address\n",
    "params_1 = {\n",
    "    \"format\": \"jsonv2\",\n",
    "    \"lat\": 30.440777,\n",
    "    \"lon\": -97.777048\n",
    "}\n",
    "\n",
    "print(\"===== Test Home Response:\")\n",
    "response = requests.get(url, params=params_1).json()\n",
    "pp.pprint(response)\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV, put into DataFrame\n",
    "latlon_df = pd.read_csv(randLatLon_csv)\n",
    "latlon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put latitudes and longitudes into a zip object\n",
    "lats = latlon_df.iloc[:, 0]\n",
    "lons = latlon_df.iloc[:, 1]\n",
    "lat_lons = []\n",
    "lat_lons = zip(lats, lons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Loop Request API for Addresses / Append to lists #####\n",
    "# Make sure to import time\n",
    "\n",
    "query_url = \"https://nominatim.openstreetmap.org/reverse?\"\n",
    "\n",
    "house_num = []\n",
    "road = []\n",
    "postcode = []\n",
    "lat = []\n",
    "lon = []\n",
    "neighborhood = []\n",
    "\n",
    "counter = 1\n",
    "numRequests = latlon_df[\"lat\"].count()\n",
    "rSuccess = []\n",
    "rFailure = []\n",
    "\n",
    "print(f\"Processing {numRequests} Requests...\")\n",
    "\n",
    "# Nominatim API Request\n",
    "\n",
    "for lat_lon in lat_lons:\n",
    "    params = {\n",
    "        \"format\": \"jsonv2\",\n",
    "        \"lat\": lat_lon[0],\n",
    "        \"lon\": lat_lon[1]\n",
    "    }\n",
    "\n",
    "    time.sleep(1.1)\n",
    "    response = requests.get(query_url, params=params).json()\n",
    "\n",
    "    if response['type'] == 'house' or response['type'] == 'yes':\n",
    "        lat.append(response['lat'])\n",
    "        lon.append(response['lon'])\n",
    "        \n",
    "        try:\n",
    "            postcode.append(response['address']['postcode'])\n",
    "        except (KeyError, IndexError):\n",
    "            postcode.append(\"NA\")\n",
    "        try:\n",
    "            house_num.append(response['address']['house_number'])\n",
    "        except (KeyError, IndexError):\n",
    "            house_num.append(\"NA\")\n",
    "        try:\n",
    "            road.append(response['address']['road'])\n",
    "        except (KeyError, IndexError):\n",
    "            road.append(\"NA\")\n",
    "        try:\n",
    "            neighborhood.append(response['address']['neighbourhood'])\n",
    "        except (KeyError, IndexError):\n",
    "            neighborhood.append(\"NA\")\n",
    "        \n",
    "        print(f\"Processed Record {counter} of {numRequests}.\")\n",
    "        rSuccess.append(counter)\n",
    "        counter += 1\n",
    "        \n",
    "    else:\n",
    "        print(f\"Wrong Type - Skipped Record {counter} of {numRequests}.\")\n",
    "        rFailure.append(counter)\n",
    "        counter += 1\n",
    "        \n",
    "print(f\"Finished Requests !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Request Results:\")\n",
    "print(\"Success #:\" + str(len(rSuccess)))\n",
    "print(\"Skipped #:\" + str(len(rFailure)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with addresses from API requests\n",
    "address_df = pd.DataFrame({\n",
    "    \"house #\": house_num,\n",
    "    \"street\": road,\n",
    "    \"zipcode\": postcode,\n",
    "    \"lat\": lat,\n",
    "    \"lon\": lon,\n",
    "    \"neighborhood\": neighborhood,\n",
    "})\n",
    "\n",
    "# Clean up Dataframe Columns before output (Drop incomplete zipcodes, Highway streets, and Null house # or streets)\n",
    "address_df = address_df[address_df['zipcode'].str.len() == 5]\n",
    "address_df = address_df[address_df['zipcode'].apply(lambda x: len(str(x)) > 3)]\n",
    "address_df = address_df[address_df['street'].str.contains(\"Highway\") == False]\n",
    "address_df = address_df[address_df['house #'].str.contains(\"NA\") == False]\n",
    "address_df = address_df[address_df['street'].str.contains(\"NA\") == False]\n",
    "address_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a CSV file of addresses\n",
    "address_df.to_csv(addressList_csv, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map out CSV with gmplot\n",
    "\n",
    "addressList_csv = \"./Data/addressList.csv\"\n",
    "\n",
    "gmap = gmplot.GoogleMapPlotter(30.27444, -97.74028, 10)\n",
    "\n",
    "gmap.scatter(addressList_csv[\"lat\"], addressList_csv[\"lon\"], 'red', size=20, marker=False)\n",
    "\n",
    "gmap.draw(\"./Visuals/myaddressmap.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zillow API Calls using Address and Zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "##### VALERIE'S BLOCKS #####\n",
    "###########################\n",
    "\n",
    "# Function for reading in csv, checking for headers, and appending if appropriate\n",
    "def csvDFappend(oldCSVfilepath, newColumn):\n",
    "    csvIN = pd.read_csv(oldCSVfilepath)\n",
    "    DF = pd.DataFrame(csvIN)\n",
    "    # Checking to ensure new header name does not match any current headers\n",
    "    colNames = DF.columns\n",
    "    for value in colNames:\n",
    "        if value == newColumn:\n",
    "            print(\"Cannot append column that matches an existing column name\")\n",
    "            return DF\n",
    "    # Check to ensure length of newColumn matches length of current dataframe columns\n",
    "    if len(newColumn) != len(DF):\n",
    "        print(\"Cannot append column that is not the same length as existing dataframe\")\n",
    "        return DF\n",
    "    # Append newColumn to Dataframe\n",
    "    DF[newColumn] = newColumn\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST BLCOK FOR FUNCTION ELEMENTS OF csvDFappend ###\n",
    "\n",
    "colNames = masterDFIMPORTclean.columns\n",
    "newCol = \"zipcode\"\n",
    "for value in colNames:\n",
    "    print(value)\n",
    "    if value == newCol:\n",
    "        print(\"Cannot append column that matches an existing column name\")\n",
    "        break\n",
    "        \n",
    "if len(address_df[\"zipcode\"]) != len(masterDFIMPORTclean):\n",
    "    print(\"Cannot append column that is not the same length as existing dataframe\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tiny sample to work with looping without exhausting API call limits\n",
    "addressListTiny_csv = \"./Data/addressListTiny.csv\"\n",
    "\n",
    "address_sample = pd.read_csv(addressListTiny_csv)\n",
    "address_df = pd.DataFrame(address_sample)\n",
    "print(len(address_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Funtion for reading CSV in as DataFrame\n",
    "def csvDF(oldCSVfilepath):\n",
    "    csvIN = pd.read_csv(oldCSVfilepath)\n",
    "    DF = pd.DataFrame(csvIN)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addressDF = csvDF(addressList_csv)\n",
    "print(len(addressDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### LOOPING FUNCTION FULLY OPERATIONAL ################\n",
    "####### HOWEVER, ZILLOW ONLY ALLOWS 1000 API CALLS PER DAY #######\n",
    "\n",
    "# Zillow API call function\n",
    "def zCall(API, index, address, zipcode):\n",
    "    APIkey = API[index]\n",
    "    zillow_data = ZillowWrapper(APIkey)\n",
    "    deep_search_response = zillow_data.get_deep_search_results(address, zipcode)\n",
    "    result = GetDeepSearchResults(deep_search_response)\n",
    "    return result\n",
    "\n",
    "# List containers for collected property data\n",
    "zid = []\n",
    "addresses = []\n",
    "alats = []\n",
    "alons = []\n",
    "valuation = []\n",
    "sqft = []\n",
    "\n",
    "# List of Zillow API keys to loop through due to daily API call limits\n",
    "zAPIs = [Zapi, Zapi01, Zapi02, Zapi03, Zapi04, Zapi05, Zapi06, Zapi07, Zapi08, Zapi09, \n",
    "         Zapi10, Zapi11, Zapi12, Zapi13, Zapi14, Zapi15, Zapi16, Zapi17, Zapi18, Zapi19, \n",
    "         Zapi20, Ztroy1, Ztroy2, Ztroy3, Zseth, Zseth2, Zkat, Zval, Zyuta]\n",
    "index = 0\n",
    "    \n",
    "for row, home in addressDF.iterrows():\n",
    "    address = str(addressDF[\"house #\"][row]) + \" \" + str(addressDF[\"street\"][row])\n",
    "    addresses.append(address)\n",
    "    zipcode = addressDF[\"zipcode\"][row]\n",
    "    print(f\"Processing {address}, {zipcode} (index {row}).\")\n",
    "    \n",
    "    result = None\n",
    "    try:\n",
    "        try:\n",
    "            result = zCall(zAPIs, index, address, zipcode)\n",
    "            print(f\"{row} Success!\")\n",
    "        except KeyError:  ### ERROR FOR API CALL LIMIT EXCEEDED ###\n",
    "            print(f\"KeyError has occurred for {address}, {zipcode} (index {row}).\")\n",
    "            index += 1\n",
    "            print(f\"Proceeding to API[{index}]\")\n",
    "            if index >= len(zAPIs):\n",
    "                print(f\"API[{index}] does not exist. Need more API keys to complete analysis.\")\n",
    "                break\n",
    "            result = zCall(zAPIs, index, address, zipcode)\n",
    "\n",
    "    except:\n",
    "        print(f\"No record found for {address}, {zipcode} (index {row}). Appending lists with null values\")\n",
    "        zid.append(None)\n",
    "        alats.append(None)\n",
    "        alons.append(None)\n",
    "        valuation.append(None)\n",
    "        sqft.append(None)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        zillowID = result.zillow_id\n",
    "        zid.append(zillowID)\n",
    "    except:\n",
    "        print(f\"No zid found for {address}, {zipcode} (index {row}). Appending list with null values\")\n",
    "        zid.append(None)\n",
    "\n",
    "    try:\n",
    "        alat = result.latitude\n",
    "        alats.append(alat)\n",
    "    except:\n",
    "        print(f\"No alat found for {address}, {zipcode} (index {row}). Appending list with null values\")\n",
    "        alats.append(None)\n",
    "\n",
    "    try:\n",
    "        alon = result.longitude\n",
    "        alons.append(alon)\n",
    "    except:\n",
    "        print(f\"No alon found for {address}, {zipcode} (index {row}). Appending list with null values\")\n",
    "        alons.append(None)\n",
    "\n",
    "    try:    \n",
    "        val = int(result.zestimate_amount)\n",
    "        valuation.append(val)\n",
    "    except:\n",
    "        print(f\"No valuation found for {address}, {zipcode} (index {row}). Appending list with null values\")\n",
    "        valuation.append(None)\n",
    "\n",
    "    try:\n",
    "        zsqft = int(result.home_size)\n",
    "        sqft.append(zsqft)\n",
    "    except:\n",
    "        print(f\"No sqft found for {address}, {zipcode} (index {row}). Appending list with null values\")\n",
    "        sqft.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(addresses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Value per Sqft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valsqft = []\n",
    "for row, value in enumerate(valuation):\n",
    "    try:\n",
    "        vsqft = round((valuation[row] / sqft[row]), 2)\n",
    "        valsqft.append(vsqft)\n",
    "    except:\n",
    "        print(\"Cannot perform math with NoneType\")\n",
    "        valsqft.append(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master Dataframe Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to ensure lists are appropriate lengths\n",
    "print(len(zid))\n",
    "print(len(alats))\n",
    "print(len(alons))\n",
    "print(len(addresses))\n",
    "print(len(valuation))\n",
    "print(len(sqft))\n",
    "print(len(valsqft))\n",
    "\n",
    "# Referring back to addressList_csv generated dataframe for relevant info\n",
    "addressDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL SAMPLE FROM 40,000 RANDOM LAT, LON GENERATION\n",
    "\n",
    "masterDF = pd.DataFrame({\n",
    "    \"Zillow ID\": zid,\n",
    "    \"address\": addresses,\n",
    "    \"zipcode\": addressDF[\"zipcode\"],\n",
    "    \"alat\": alats,\n",
    "    \"alon\": alons,\n",
    "    \"valuation\": valuation,\n",
    "    \"sqft\": sqft,\n",
    "    \"value sqft\": valsqft,\n",
    "    \"neighborhood\": addressDF[\"neighborhood\"],\n",
    "})\n",
    "print(len(masterDF))\n",
    "masterDF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterDFclean = masterDF.dropna(how=\"any\", subset=[\"Zillow ID\"])\n",
    "len(masterDFclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masterDF to csv\n",
    "masterDFclean.to_csv(masterData_csv, index=False, header=True)\n",
    "masterDFclean.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONTINUE HERE READ IN NEW CSV TO CLEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterDFdrops = masterDFclean.dropna(how=\"any\", subset=[\"value sqft\"])\n",
    "len(masterDFdrops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterDFdrops = masterDFdrops.dropna(how=\"any\", subset=[\"sqft\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterDFdrops.sort_values(by=\"value sqft\", ascending=False)\n",
    "# masterDFIMPORTclean.to_csv(\"./Data/masterDFIMPORTclean.csv\", index=False, header=True)\n",
    "# masterDFIMPORTclean.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kat's section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## School Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seth's section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troy's section\n",
    "\n",
    "\n",
    "gmaps.configure(api_key=google_API_Key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell creates a test masterData_df by pulling in Yuta's address file and adds a column as a testm \"value to map\"\n",
    "# This cell can be deleted as soon as there is a master data file that includes a property value column or some other value to plot\n",
    "# The last digit of the zipcode is used as a value that will vary by area and a random number between 0 and 1 is added to create variation in the weights\n",
    "\n",
    "masterData_df = pd.read_csv(addressList_csv)\n",
    "zips = masterData_df[\"zipcode\"]\n",
    "valueToMap = []\n",
    "\n",
    "for zip in zips:\n",
    "    lastDigit = zip[-1:]\n",
    "#    print(last2Digits)\n",
    "    valueToMap.append(int(lastDigit) + random.uniform(0.0,1.0))\n",
    "    \n",
    "masterData_df[\"valueToMap\"] = valueToMap\n",
    "masterData_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell uses gmaps library to create a google heat map from the data in a master data file.\n",
    "# The masterData csv file is taken as input\n",
    "# The lat and lon columns are taken as the coordinates for hte heatmap \n",
    "# The user specified column is taken as the weighting valies fo each coordinate point\n",
    "\n",
    "df = masterData_df\n",
    "columnToMap = 'valueToMap'\n",
    "max_intensity = df[columnToMap].max()\n",
    "\n",
    "fig = gmaps.figure()\n",
    "heatmap_layer = gmaps.heatmap_layer(df[['lat', 'lon']], weights=df[columnToMap], max_intensity=max_intensity, point_radius=10.0)\n",
    "fig.add_layer(heatmap_layer)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a function version of the cell above\n",
    "# the function takes columnToMap as the weights for the points defined by 'lat' and 'lon' columns in the dataframe\n",
    "# the dataframe can be included as a parameter, if it is not included masterData_df is assumed\n",
    "\n",
    "def heatMapper(columnToMap, df = masterData_df):\n",
    "    \n",
    "    max_intensity = df[columnToMap].max()\n",
    "    \n",
    "    fig = gmaps.figure()\n",
    "    heatmap_layer = gmaps.heatmap_layer(df[['lat', 'lon']], weights=df[columnToMap], max_intensity=max_intensity, point_radius=10.0)\n",
    "    fig.add_layer(heatmap_layer)\n",
    "\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatMapper(columnToMap = 'valueToMap')\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
